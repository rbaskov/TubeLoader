import { exec, spawn } from "child_process";
import { promisify } from "util";
import * as fs from "fs";
import * as path from "path";

const execAsync = promisify(exec);

const DOWNLOADS_DIR = path.join(process.cwd(), "downloads");
const YTDLP_PATH = path.join(process.cwd(), "yt-dlp");

if (!fs.existsSync(DOWNLOADS_DIR)) {
  fs.mkdirSync(DOWNLOADS_DIR, { recursive: true });
}

export interface VideoInfo {
  title: string;
  thumbnail: string;
  duration: number;
  uploader: string;
}

export interface DownloadProgress {
  status: "downloading" | "converting" | "completed" | "failed";
  progress: number;
  speed?: string;
  eta?: string;
  filename?: string;
  fileSize?: number;
  error?: string;
}

// Try multiple player clients in order - android_sdkless works best with SABR protection
const PLAYER_CLIENTS = ["android_sdkless", "ios", "android", "web"];
const COOKIES_FILE = path.join(process.cwd(), "cookies.txt");

// Proxy configuration interface
export interface ProxyConfig {
  enabled: boolean;
  type: "http" | "https" | "socks4" | "socks5";
  host: string;
  port: number;
  username?: string;
  password?: string;
}

// Build proxy URL for yt-dlp
function buildProxyUrl(config: ProxyConfig): string {
  if (!config.enabled || !config.host || !config.port) {
    return "";
  }
  
  let auth = "";
  if (config.username && config.password) {
    auth = `${encodeURIComponent(config.username)}:${encodeURIComponent(config.password)}@`;
  } else if (config.username) {
    auth = `${encodeURIComponent(config.username)}@`;
  }
  
  return `${config.type}://${auth}${config.host}:${config.port}`;
}

// Cookie interface for JSON format
interface JsonCookie {
  domain: string;
  expirationDate?: number;
  hostOnly?: boolean;
  httpOnly?: boolean;
  name: string;
  path: string;
  sameSite?: string;
  secure?: boolean;
  session?: boolean;
  storeId?: string;
  value: string;
}

// Convert JSON cookies to Netscape format
function jsonToNetscape(cookies: JsonCookie[]): string {
  const lines = [
    "# Netscape HTTP Cookie File",
    "# This file is generated by yt-dlp.  Do not edit.",
    ""
  ];
  
  for (const cookie of cookies) {
    // Netscape format: domain, flag, path, secure, expiration, name, value
    const domain = cookie.domain;
    const flag = cookie.hostOnly === false ? "TRUE" : "FALSE";
    const path = cookie.path || "/";
    const secure = cookie.secure ? "TRUE" : "FALSE";
    const expiration = cookie.expirationDate ? Math.floor(cookie.expirationDate) : 0;
    const name = cookie.name;
    const value = cookie.value;
    
    lines.push(`${domain}\t${flag}\t${path}\t${secure}\t${expiration}\t${name}\t${value}`);
  }
  
  return lines.join('\n');
}

// Save cookies to file for yt-dlp (supports both JSON and Netscape formats)
export function saveCookies(cookiesContent: string): void {
  let finalContent: string;
  const trimmed = cookiesContent.trim();
  
  // Detect JSON format (starts with [ and ends with ])
  if (trimmed.startsWith('[') && trimmed.endsWith(']')) {
    try {
      const jsonCookies: JsonCookie[] = JSON.parse(trimmed);
      finalContent = jsonToNetscape(jsonCookies);
      console.log(`Converted ${jsonCookies.length} JSON cookies to Netscape format`);
    } catch (e) {
      console.error("Failed to parse JSON cookies:", e);
      throw new Error("Invalid JSON cookies format");
    }
  } else {
    // Netscape format - fix tab separation if needed
    const lines = cookiesContent.split('\n');
    const fixedLines = lines.map(line => {
      // Skip comment and empty lines
      if (line.startsWith('#') || line.trim() === '') {
        return line;
      }
      
      // Cookie lines should have 7 fields separated by tabs
      const fields = line.split(/\t+/);
      if (fields.length === 7) {
        return line;
      }
      
      // Try splitting by multiple spaces
      const spaceFields = line.split(/\s{2,}|\t/);
      if (spaceFields.length >= 7) {
        const fixedFields = spaceFields.slice(0, 6);
        fixedFields.push(spaceFields.slice(6).join(' '));
        return fixedFields.join('\t');
      }
      
      return line;
    });
    finalContent = fixedLines.join('\n');
  }
  
  fs.writeFileSync(COOKIES_FILE, finalContent, "utf-8");
  console.log("Cookies saved to", COOKIES_FILE);
}

// Check if cookies file exists
export function hasCookies(): boolean {
  return fs.existsSync(COOKIES_FILE) && fs.statSync(COOKIES_FILE).size > 0;
}

export async function getVideoInfo(url: string, proxyConfig?: ProxyConfig): Promise<VideoInfo> {
  let lastError: Error | null = null;
  const useCookies = hasCookies();
  const proxyUrl = proxyConfig ? buildProxyUrl(proxyConfig) : "";
  
  for (const client of PLAYER_CLIENTS) {
    try {
      console.log(`Trying player client: ${client}${useCookies ? " with cookies" : ""}${proxyUrl ? " with proxy" : ""}`);
      
      // Use -j (same as --dump-json) with --skip-download and -f any to avoid format selection issues
      // Also add --ignore-no-formats-error for HLS-only videos
      let cmd = `"${YTDLP_PATH}" -j --skip-download --no-warnings --ignore-no-formats-error --extractor-args "youtube:player_client=${client}"`;
      if (useCookies) {
        cmd += ` --cookies "${COOKIES_FILE}"`;
      }
      if (proxyUrl) {
        cmd += ` --proxy "${proxyUrl}"`;
      }
      cmd += ` "${url}"`;
      
      const { stdout } = await execAsync(cmd, { maxBuffer: 10 * 1024 * 1024, timeout: 60000 });
      
      const info = JSON.parse(stdout);
      console.log(`Success with player client: ${client}`);
      
      return {
        title: info.title || "Unknown Title",
        thumbnail: info.thumbnail || "",
        duration: info.duration || 0,
        uploader: info.uploader || "Unknown",
      };
    } catch (error) {
      console.error(`Error with player client ${client}:`, (error as Error).message);
      lastError = error as Error;
    }
  }
  
  console.error("All player clients failed:", lastError);
  throw new Error(`Failed to get video info: ${lastError?.message}`);
}

export function downloadVideo(
  url: string,
  jobId: string,
  format: "video" | "audio",
  quality: string | null,
  onProgress: (progress: DownloadProgress) => void,
  proxyConfig?: ProxyConfig
): Promise<{ filePath: string; fileSize: number }> {
  return new Promise((resolve, reject) => {
    const outputTemplate = path.join(DOWNLOADS_DIR, `${jobId}.%(ext)s`);
    
    const useCookies = hasCookies();
    const proxyUrl = proxyConfig ? buildProxyUrl(proxyConfig) : "";
    
    // Use android_sdkless client - best compatibility with YouTube's SABR protection
    // This client provides direct download URLs without requiring JavaScript runtime
    const playerClient = "android_sdkless";
    
    const args: string[] = [
      "--no-playlist",
      "--newline",
      "--progress",
      "--no-check-certificates",
      "--prefer-free-formats",
      "--no-warnings",
      "--ignore-no-formats-error",
      "--extractor-args", `youtube:player_client=${playerClient}`,
      "-o", outputTemplate,
    ];

    // Add proxy if configured
    if (proxyUrl) {
      args.push("--proxy", proxyUrl);
      console.log(`Using proxy for download: ${proxyConfig?.type}://${proxyConfig?.host}:${proxyConfig?.port}`);
    }

    // Add cookies if available
    if (useCookies) {
      args.push("--cookies", COOKIES_FILE);
      console.log(`Using cookies file for download with ${playerClient} client`);
    }

    if (format === "audio") {
      args.push("-x", "--audio-format", "mp3", "--audio-quality", "0");
    } else {
      // Format selection with HLS fallback for SABR-protected videos
      // Priority: direct formats > HLS streams > any available format
      // HLS (m3u8) works with cookies when direct formats are blocked
      if (quality === "1080p") {
        args.push("-f", "bv*[height<=1080]+ba/b[height<=1080]/best[protocol=m3u8][height<=1080]/best[protocol=m3u8]/bv*+ba/b");
      } else if (quality === "720p") {
        args.push("-f", "bv*[height<=720]+ba/b[height<=720]/best[protocol=m3u8][height<=720]/best[protocol=m3u8]/bv*+ba/b");
      } else if (quality === "480p") {
        args.push("-f", "bv*[height<=480]+ba/b[height<=480]/best[protocol=m3u8][height<=480]/best[protocol=m3u8]/bv*+ba/b");
      } else {
        args.push("-f", "bv*+ba/best[protocol=m3u8]/b");
      }
    }

    args.push(url);

    console.log(`Starting yt-dlp (${YTDLP_PATH}) with args: ${args.join(" ")}`);

    const ytdlp = spawn(YTDLP_PATH, args);

    let lastProgress = 0;
    let currentStatus: "downloading" | "converting" = "downloading";
    let outputFilePath = "";
    let stderrOutput = "";
    let lastSpeed = "";
    let lastEta = "";

    const parseProgress = (line: string) => {
      // Parse download progress with speed and ETA
      // Format: [download]   0.0% of   20.09MiB at  342.03KiB/s ETA 01:00
      if (line.includes("[download]") && line.includes("%")) {
        // Extract percentage
        const percentMatch = line.match(/(\d+\.?\d*)%/);
        // Extract speed (e.g., "342.03KiB/s" or "10.33MiB/s")
        const speedMatch = line.match(/at\s+([\d.]+\s*[KMG]?i?B\/s)/i);
        // Extract ETA (e.g., "01:00" or "00:05")
        const etaMatch = line.match(/ETA\s+(\d+:\d+)/);
        
        if (percentMatch) {
          const progress = parseFloat(percentMatch[1]);
          const speed = speedMatch ? speedMatch[1] : lastSpeed;
          const eta = etaMatch ? etaMatch[1] : lastEta;
          
          // Update last known values
          if (speedMatch && !speedMatch[1].includes("Unknown")) {
            lastSpeed = speedMatch[1];
          }
          if (etaMatch) {
            lastEta = etaMatch[1];
          }
          
          // Only update if progress increased (monotonic)
          if (progress >= lastProgress) {
            lastProgress = progress;
            onProgress({
              status: "downloading",
              progress: Math.min(progress * 0.9, 90),
              speed: speed || undefined,
              eta: eta || undefined,
            });
          }
        }
      }
      
      // Parse merging/converting status
      if (line.includes("[Merger]") || line.includes("[ffmpeg]") || line.includes("Merging")) {
        currentStatus = "converting";
        onProgress({
          status: "converting",
          progress: 92,
        });
      }
      
      // Parse destination file
      if (line.includes("Destination:")) {
        const destMatch = line.match(/Destination:\s*(.+)/);
        if (destMatch) {
          outputFilePath = destMatch[1].trim();
        }
      }
      
      // Parse completion
      if (line.includes("[download] 100%") || line.includes("has already been downloaded")) {
        onProgress({
          status: "converting",
          progress: 95,
        });
      }
    };

    ytdlp.stdout.on("data", (data: Buffer) => {
      const lines = data.toString().split("\n");
      for (const line of lines) {
        console.log(`yt-dlp stdout: ${line}`);
        parseProgress(line);
      }
    });

    ytdlp.stderr.on("data", (data: Buffer) => {
      const text = data.toString();
      stderrOutput += text;
      console.error(`yt-dlp stderr: ${text}`);
      // Also try to parse progress from stderr (some output goes here)
      const lines = text.split("\n");
      for (const line of lines) {
        parseProgress(line);
      }
    });

    ytdlp.on("close", async (code) => {
      if (code !== 0) {
        const errorDetails = stderrOutput.trim().split('\n').slice(-5).join(' ') || `exit code ${code}`;
        const errorMsg = `Download failed: ${errorDetails}`.substring(0, 500);
        onProgress({
          status: "failed",
          progress: 0,
          error: errorMsg,
        });
        reject(new Error(errorMsg));
        return;
      }

      try {
        const expectedExt = format === "audio" ? "mp3" : "mp4";
        let finalPath = path.join(DOWNLOADS_DIR, `${jobId}.${expectedExt}`);
        
        if (!fs.existsSync(finalPath)) {
          const files = fs.readdirSync(DOWNLOADS_DIR);
          const matchingFile = files.find(f => f.startsWith(jobId));
          if (matchingFile) {
            finalPath = path.join(DOWNLOADS_DIR, matchingFile);
          }
        }

        if (!fs.existsSync(finalPath)) {
          throw new Error(`Output file not found: ${finalPath}`);
        }

        const stats = fs.statSync(finalPath);
        
        onProgress({
          status: "completed",
          progress: 100,
          filename: path.basename(finalPath),
          fileSize: stats.size,
        });

        resolve({
          filePath: finalPath,
          fileSize: stats.size,
        });
      } catch (error) {
        onProgress({
          status: "failed",
          progress: 0,
          error: (error as Error).message,
        });
        reject(error);
      }
    });

    ytdlp.on("error", (error) => {
      console.error("yt-dlp spawn error:", error);
      onProgress({
        status: "failed",
        progress: 0,
        error: error.message,
      });
      reject(error);
    });
  });
}

export function getDownloadFilePath(jobId: string, format: "video" | "audio"): string | null {
  const expectedExt = format === "audio" ? "mp3" : "mp4";
  const expectedPath = path.join(DOWNLOADS_DIR, `${jobId}.${expectedExt}`);
  
  if (fs.existsSync(expectedPath)) {
    return expectedPath;
  }
  
  const files = fs.readdirSync(DOWNLOADS_DIR);
  const matchingFile = files.find(f => f.startsWith(jobId));
  if (matchingFile) {
    return path.join(DOWNLOADS_DIR, matchingFile);
  }
  
  return null;
}

export function cleanupDownloadFile(jobId: string): void {
  try {
    const files = fs.readdirSync(DOWNLOADS_DIR);
    for (const file of files) {
      if (file.startsWith(jobId)) {
        fs.unlinkSync(path.join(DOWNLOADS_DIR, file));
        console.log(`Cleaned up file: ${file}`);
      }
    }
  } catch (error) {
    console.error(`Error cleaning up files for job ${jobId}:`, error);
  }
}

const MIN_FREE_SPACE_GB = 5;
const MIN_FREE_SPACE_BYTES = MIN_FREE_SPACE_GB * 1024 * 1024 * 1024;

export interface DiskSpaceInfo {
  freeBytes: number;
  totalBytes: number;
  freeGB: number;
}

export async function getDiskSpace(): Promise<DiskSpaceInfo> {
  try {
    const { stdout } = await execAsync(`df -B1 "${DOWNLOADS_DIR}" | tail -1 | awk '{print $4, $2}'`);
    const [free, total] = stdout.trim().split(/\s+/).map(s => parseInt(s, 10));
    return {
      freeBytes: free || 0,
      totalBytes: total || 0,
      freeGB: (free || 0) / (1024 * 1024 * 1024),
    };
  } catch (error) {
    console.error("Error getting disk space:", error);
    return { freeBytes: 0, totalBytes: 0, freeGB: 0 };
  }
}

export interface FileWithStats {
  filePath: string;
  jobId: string;
  size: number;
  mtime: Date;
}

export async function getDownloadFiles(): Promise<FileWithStats[]> {
  try {
    if (!fs.existsSync(DOWNLOADS_DIR)) return [];
    
    const files = fs.readdirSync(DOWNLOADS_DIR);
    const fileStats: FileWithStats[] = [];
    
    for (const file of files) {
      const filePath = path.join(DOWNLOADS_DIR, file);
      try {
        const stats = fs.statSync(filePath);
        if (stats.isFile()) {
          // Extract jobId from filename (format: jobId.ext)
          const jobId = file.replace(/\.[^/.]+$/, "");
          fileStats.push({
            filePath,
            jobId,
            size: stats.size,
            mtime: stats.mtime,
          });
        }
      } catch {
        // Skip files that can't be read
      }
    }
    
    // Sort by modification time, oldest first
    return fileStats.sort((a, b) => a.mtime.getTime() - b.mtime.getTime());
  } catch (error) {
    console.error("Error getting download files:", error);
    return [];
  }
}

export async function autoCleanupIfNeeded(
  getUploadedJobIds: () => Promise<string[]>
): Promise<{ cleaned: boolean; freedBytes: number; deletedFiles: string[] }> {
  const diskSpace = await getDiskSpace();
  
  if (diskSpace.freeBytes >= MIN_FREE_SPACE_BYTES) {
    console.log(`Disk space OK: ${diskSpace.freeGB.toFixed(2)} GB free`);
    return { cleaned: false, freedBytes: 0, deletedFiles: [] };
  }
  
  console.log(`Low disk space: ${diskSpace.freeGB.toFixed(2)} GB free. Starting cleanup...`);
  
  // Get job IDs that have been uploaded to NAS
  const uploadedJobIds = await getUploadedJobIds();
  const uploadedJobIdSet = new Set(uploadedJobIds);
  
  const files = await getDownloadFiles();
  let freedBytes = 0;
  const deletedFiles: string[] = [];
  
  // Delete oldest files first, but only if they've been uploaded to NAS
  for (const file of files) {
    // Only delete files that have been uploaded to NAS
    if (!uploadedJobIdSet.has(file.jobId)) {
      console.log(`Skipping ${file.jobId} - not yet uploaded to NAS`);
      continue;
    }
    
    try {
      fs.unlinkSync(file.filePath);
      freedBytes += file.size;
      deletedFiles.push(file.filePath);
      console.log(`Deleted old file: ${file.filePath} (${(file.size / 1024 / 1024).toFixed(2)} MB)`);
      
      // Check if we have enough space now
      const newDiskSpace = await getDiskSpace();
      if (newDiskSpace.freeBytes >= MIN_FREE_SPACE_BYTES) {
        console.log(`Cleanup complete: ${newDiskSpace.freeGB.toFixed(2)} GB free`);
        break;
      }
    } catch (error) {
      console.error(`Error deleting file ${file.filePath}:`, error);
    }
  }
  
  console.log(`Cleanup freed ${(freedBytes / 1024 / 1024).toFixed(2)} MB, deleted ${deletedFiles.length} files`);
  return { cleaned: true, freedBytes, deletedFiles };
}
